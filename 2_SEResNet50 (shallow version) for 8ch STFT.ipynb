{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T10:42:40.211350Z",
     "start_time": "2019-12-13T10:42:39.697145Z"
    }
   },
   "source": [
    "__Skip Connection / Bottleneck Skip connection__\n",
    "\n",
    "![image](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F99F0453F5C47F1741338F0)\n",
    "\n",
    "- ResNet50 부터는 연산량의 줄이기 위해 Residual Block 내에, 1x1, 3x3, 1x1 컨볼루션 연산을 쌓았다. Inception에서 배웠던 것과 같은 개념이다. 1x1 컨볼루션 연산으로 피쳐맵의 갯수를 줄였다가 3x3을 거친 후, 1x1 컨볼루션 연산으로 차원을 늘려준다. 이 과정이 병목 같다 하여 병목레이어(bottleneck layer)라고 부른다.\n",
    "\n",
    "__Residual Block / Identity Block__\n",
    "\n",
    "![image](https://datascienceschool.net/upfiles/2e104ff279804e839cef46fc58ef16e7.png)\n",
    "\n",
    "-  이미지가 반으로 작아진 경우, Identity Block이 사용되며, 입력값을 바로 더하지 않고, 1x1 컨볼루션 연산을 스트라이드 2로 설정하여 피쳐맵의 크기와 갯수를 맞추어준 다음 더해준다. 이를 프로젝션 숏컷(projection shortcut)\n",
    "\n",
    "__ResNet Structrue by layer__\n",
    "\n",
    "![image](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99167C335C47F0E315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SENet (SE block)__\n",
    "\n",
    "![image](https://i.imgur.com/9UFjxDA.png)\n",
    "\n",
    "__SE block in ResNet__\n",
    "![image](https://t1.daumcdn.net/cfile/tistory/9917F14A5D3EB6D535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:23.354368Z",
     "start_time": "2019-12-14T21:07:21.509639Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPU setting\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "# modules setting\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import datetime\n",
    "from utils import one_hot, train_valid_split, random_minibatch, shuffle, history\n",
    "from utils import training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:34.074241Z",
     "start_time": "2019-12-14T21:07:34.063397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dball_7.npy',\n",
       " 'dball_14.npy',\n",
       " 'dball_21.npy',\n",
       " 'dinner_7.npy',\n",
       " 'dinner_14.npy',\n",
       " 'dinner_21.npy',\n",
       " 'douter_7.npy',\n",
       " 'douter_14.npy',\n",
       " 'douter_21.npy',\n",
       " 'normal.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir =  '/mnt/disk1/yunseob/courses/19-2_computer vision/data/STFT/ch/train'\n",
    "npy_files = os.listdir(train_dir)\n",
    "npy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:38.692692Z",
     "start_time": "2019-12-14T21:07:36.345802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: (600, 100, 100, 8) (600, 10)\n",
      "ball_7: (600, 100, 100, 8) (600, 10)\n",
      "ball_14: (600, 100, 100, 8) (600, 10)\n",
      "ball_21: (600, 100, 100, 8) (600, 10)\n",
      "inner_7: (600, 100, 100, 8) (600, 10)\n",
      "inner_14: (600, 100, 100, 8) (600, 10)\n",
      "inner_21: (600, 100, 100, 8) (600, 10)\n",
      "outer_7: (600, 100, 100, 8) (600, 10)\n",
      "outer_14: (600, 100, 100, 8) (600, 10)\n",
      "outer_21: (600, 100, 100, 8) (600, 10)\n"
     ]
    }
   ],
   "source": [
    "normal = np.load(os.path.join(train_dir, str([i for i in npy_files if 'normal' in i][0])))\n",
    "ball_7 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'ball_7' in i][0])))\n",
    "ball_14 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'ball_14' in i][0])))\n",
    "ball_21 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'ball_21' in i][0])))\n",
    "inner_7 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'inner_7' in i][0])))\n",
    "inner_14 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'inner_14' in i][0])))\n",
    "inner_21 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'inner_21' in i][0])))\n",
    "outer_7 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'outer_7' in i][0])))\n",
    "outer_14 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'outer_14' in i][0])))\n",
    "outer_21 = np.load(os.path.join(train_dir, str([i for i in npy_files if 'outer_21' in i][0])))\n",
    "\n",
    "normal_y = one_hot(normal, 0, nb_classes = 10)\n",
    "ball_7_y = one_hot(ball_7, 1, nb_classes = 10)\n",
    "ball_14_y = one_hot(ball_14, 2, nb_classes = 10)\n",
    "ball_21_y = one_hot(ball_21, 3, nb_classes = 10)\n",
    "inner_7_y = one_hot(inner_7, 4, nb_classes = 10)\n",
    "inner_14_y = one_hot(inner_14, 5, nb_classes = 10)\n",
    "inner_21_y = one_hot(inner_21, 6, nb_classes = 10)\n",
    "outer_7_y = one_hot(outer_7, 7, nb_classes = 10)\n",
    "outer_14_y = one_hot(outer_14, 8, nb_classes = 10)\n",
    "outer_21_y = one_hot(outer_21, 9, nb_classes = 10)\n",
    "\n",
    "print(\"normal:\", normal.shape, normal_y.shape)\n",
    "print(\"ball_7:\", ball_7.shape, ball_7_y.shape)\n",
    "print(\"ball_14:\", ball_14.shape, ball_14_y.shape)\n",
    "print(\"ball_21:\", ball_21.shape, ball_21_y.shape)\n",
    "print(\"inner_7:\", inner_7.shape, inner_7_y.shape)\n",
    "print(\"inner_14:\", inner_14.shape, inner_14_y.shape)\n",
    "print(\"inner_21:\", inner_21.shape, inner_21_y.shape)\n",
    "print(\"outer_7:\", outer_7.shape, outer_7_y.shape)\n",
    "print(\"outer_14:\", outer_14.shape, outer_14_y.shape)\n",
    "print(\"outer_21:\", outer_21.shape, outer_21_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:44.606606Z",
     "start_time": "2019-12-14T21:07:42.528999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "ball_7: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "ball_14: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "ball_21: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "inner_7: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "inner_14: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "inner_21: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "outer_7: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "outer_14: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n",
      "outer_21: (510, 100, 100, 8) (510, 10) (90, 100, 100, 8) (90, 10)\n"
     ]
    }
   ],
   "source": [
    "normal_train_x, normal_train_y, normal_valid_x, normal_valid_y = train_valid_split(normal, normal_y)\n",
    "print(\"normal:\", normal_train_x.shape, normal_train_y.shape, normal_valid_x.shape, normal_valid_y.shape)\n",
    "\n",
    "ball_7_train_x, ball_7_train_y, ball_7_valid_x, ball_7_valid_y = train_valid_split(ball_7, ball_7_y)\n",
    "ball_14_train_x, ball_14_train_y, ball_14_valid_x, ball_14_valid_y = train_valid_split(ball_14, ball_14_y)\n",
    "ball_21_train_x, ball_21_train_y, ball_21_valid_x, ball_21_valid_y = train_valid_split(ball_21, ball_21_y)\n",
    "print(\"ball_7:\", ball_7_train_x.shape, ball_7_train_y.shape, ball_7_valid_x.shape, ball_7_valid_y.shape)\n",
    "print(\"ball_14:\", ball_14_train_x.shape, ball_14_train_y.shape, ball_14_valid_x.shape, ball_14_valid_y.shape)\n",
    "print(\"ball_21:\", ball_21_train_x.shape, ball_21_train_y.shape, ball_21_valid_x.shape, ball_21_valid_y.shape)\n",
    "\n",
    "inner_7_train_x, inner_7_train_y, inner_7_valid_x, inner_7_valid_y = train_valid_split(inner_7, inner_7_y)\n",
    "inner_14_train_x, inner_14_train_y, inner_14_valid_x, inner_14_valid_y = train_valid_split(inner_14, inner_14_y)\n",
    "inner_21_train_x, inner_21_train_y, inner_21_valid_x, inner_21_valid_y = train_valid_split(inner_21, inner_21_y)\n",
    "print(\"inner_7:\", inner_7_train_x.shape, inner_7_train_y.shape, inner_7_valid_x.shape, inner_7_valid_y.shape)\n",
    "print(\"inner_14:\", inner_14_train_x.shape, inner_14_train_y.shape, inner_14_valid_x.shape, inner_14_valid_y.shape)\n",
    "print(\"inner_21:\", inner_21_train_x.shape, inner_21_train_y.shape, inner_21_valid_x.shape, inner_21_valid_y.shape)\n",
    "\n",
    "outer_7_train_x, outer_7_train_y, outer_7_valid_x, outer_7_valid_y = train_valid_split(outer_7, outer_7_y)\n",
    "outer_14_train_x, outer_14_train_y, outer_14_valid_x, outer_14_valid_y = train_valid_split(outer_14, outer_14_y)\n",
    "outer_21_train_x, outer_21_train_y, outer_21_valid_x, outer_21_valid_y = train_valid_split(outer_21, outer_21_y)\n",
    "print(\"outer_7:\", outer_7_train_x.shape, outer_7_train_y.shape, outer_7_valid_x.shape, outer_7_valid_y.shape)\n",
    "print(\"outer_14:\", outer_14_train_x.shape, outer_14_train_y.shape, outer_14_valid_x.shape, outer_14_valid_y.shape)\n",
    "print(\"outer_21:\", outer_21_train_x.shape, outer_21_train_y.shape, outer_21_valid_x.shape, outer_21_valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:49.289112Z",
     "start_time": "2019-12-14T21:07:46.744300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (5100, 100, 100, 8) (5100, 10)\n",
      "Validation set: (900, 100, 100, 8) (900, 10)\n"
     ]
    }
   ],
   "source": [
    "train_X = np.vstack([normal_train_x, ball_7_train_x, ball_14_train_x, ball_21_train_x, \n",
    "                     inner_7_train_x, inner_14_train_x, inner_21_train_x,\n",
    "                     outer_7_train_x, outer_14_train_x, outer_21_train_x, ])\n",
    "train_Y = np.vstack([normal_train_y, ball_7_train_y, ball_14_train_y, ball_21_train_y, \n",
    "                     inner_7_train_y, inner_14_train_y, inner_21_train_y,\n",
    "                     outer_7_train_y, outer_14_train_y, outer_21_train_y, ])\n",
    "valid_X = np.vstack([normal_valid_x, ball_7_valid_x, ball_14_valid_x, ball_21_valid_x, \n",
    "                     inner_7_valid_x, inner_14_valid_x, inner_21_valid_x,\n",
    "                     outer_7_valid_x, outer_14_valid_x, outer_21_valid_x, ])\n",
    "valid_Y = np.vstack([normal_valid_y, ball_7_valid_y, ball_14_valid_y, ball_21_valid_y, \n",
    "                     inner_7_valid_y, inner_14_valid_y, inner_21_valid_y,\n",
    "                     outer_7_valid_y, outer_14_valid_y, outer_21_valid_y, ])\n",
    "\n",
    "print(\"Training set:\", train_X.shape, train_Y.shape)\n",
    "print(\"Validation set:\", valid_X.shape, valid_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:53.207434Z",
     "start_time": "2019-12-14T21:07:53.200364Z"
    }
   },
   "outputs": [],
   "source": [
    "input_h = 100\n",
    "input_w = 100\n",
    "input_ch = 8\n",
    "\n",
    "ch = 16\n",
    "# 50 50 16\n",
    "\n",
    "r_ch_1 = 32\n",
    "# 25 25 32\n",
    "\n",
    "r_ch_2 = 32\n",
    "# 12 12 16\n",
    "\n",
    "r_ch_3 = 64\n",
    "# 12 12 32\n",
    "\n",
    "r_ch_4 = 128\n",
    "# 6 6 128\n",
    "\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:07:59.306245Z",
     "start_time": "2019-12-14T21:07:53.788804Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1215 06:07:53.840804 139752795641600 deprecation.py:323] From <ipython-input-8-9c0902bb28ba>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W1215 06:07:53.845405 139752795641600 deprecation.py:506] From /home/yunseob/.local/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1215 06:07:54.034661 139752795641600 deprecation.py:323] From <ipython-input-8-9c0902bb28ba>:17: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W1215 06:07:54.113371 139752795641600 deprecation.py:323] From <ipython-input-8-9c0902bb28ba>:23: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W1215 06:07:54.764859 139752795641600 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1215 06:07:54.766176 139752795641600 deprecation.py:323] From <ipython-input-8-9c0902bb28ba>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W1215 06:07:59.076846 139752795641600 deprecation.py:323] From <ipython-input-8-9c0902bb28ba>:62: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W1215 06:07:59.294495 139752795641600 deprecation.py:323] From /home/yunseob/.local/lib/python3.5/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, input_h, input_w, input_ch], name = 'img')\n",
    "y = tf.placeholder(tf.float32, [None, n_output], name = 'label')\n",
    "batch_prob = tf.placeholder(tf.bool, name = 'bn_prob')\n",
    "\n",
    "class SEResNet50:\n",
    "    def __init__(self, ch, r_ch_1, r_ch_2, r_ch_3, r_ch_4):\n",
    "        self.ch = ch\n",
    "        self.r_ch_1 = r_ch_1\n",
    "        self.r_ch_2 = r_ch_2\n",
    "        self.r_ch_3 = r_ch_3\n",
    "        self.r_ch_4 = r_ch_4\n",
    "    def conv(self, x, channel, kernel_size = [3, 3], strides = (1, 1), activation = True):\n",
    "        conv = tf.layers.conv2d(inputs = x, filters = channel, kernel_size = kernel_size, \n",
    "                                strides = strides, padding = \"SAME\")\n",
    "        conv = tf.layers.batch_normalization(conv, center=True, scale=True, training=batch_prob)\n",
    "        if activation == True:\n",
    "            conv = tf.nn.relu(conv)\n",
    "        return conv\n",
    "    \n",
    "    def maxp(self, conv):\n",
    "        maxp = tf.layers.max_pooling2d(inputs = conv, pool_size = [2, 2], strides = 2)\n",
    "        return maxp\n",
    "\n",
    "    def SE_block(self, x, channel = None, reduction_ratio = 4):\n",
    "        ch_reduced = channel/reduction_ratio\n",
    "        x_in = x\n",
    "        squeeze = self.global_avg_pooling(x_in)\n",
    "        excitation =  tf.layers.dense(inputs = squeeze, units = ch_reduced, \n",
    "                                      kernel_initializer = tf.contrib.layers.variance_scaling_initializer(uniform=False, factor=2.0, mode='FAN_IN', dtype=tf.float32),\n",
    "                                      activation = tf.nn.relu, use_bias = False)\n",
    "        excitation =  tf.layers.dense(inputs = excitation, units = channel, \n",
    "                                      kernel_initializer = tf.contrib.layers.variance_scaling_initializer(uniform=False, factor=2.0, mode='FAN_IN', dtype=tf.float32),\n",
    "                                      activation = tf.nn.sigmoid, use_bias = False)\n",
    "#         excitation =  tf.layers.dense(inputs = squeeze, units = ch_reduced, activation = tf.nn.relu, use_bias = False)\n",
    "#         excitation =  tf.layers.dense(inputs = excitation, units = channel, activation = tf.nn.sigmoid, use_bias = False)\n",
    "        excitation = tf.reshape(excitation, [-1, 1, 1, channel])\n",
    "        scale = tf.multiply(x_in, excitation)\n",
    "        \n",
    "        return scale\n",
    "\n",
    "    def SE_res_block(self, x, channel, strides = (1, 1), reduction_ratio = 4):\n",
    "        conv_a = self.conv(x, channel/4, kernel_size = [1, 1], strides = strides)\n",
    "        conv_b = self.conv(conv_a, channel/4, kernel_size = [3, 3])\n",
    "        conv_c = self.conv(conv_b, channel, kernel_size = [1, 1], activation = False)\n",
    "        se = self.SE_block(conv_c, channel, reduction_ratio = 4)\n",
    "\n",
    "        proj_input = self.conv(x, channel, kernel_size = [1, 1], strides = strides, activation = False)\n",
    "        \n",
    "        return tf.nn.relu(proj_input + se)\n",
    "    \n",
    "    def SE_res_stage(self, x, target_ch, reduction_ratio = 4, downsample = False, n_rep = None):\n",
    "        strides = (2, 2) if downsample != False else (1, 1)\n",
    "       \n",
    "        x = self.SE_res_block(x, target_ch, strides)\n",
    "        for _ in range(n_rep-1):\n",
    "            x = self.SE_res_block(x, target_ch)\n",
    "        return x\n",
    "\n",
    "    def fc_layer(self, gap, n_output = None):\n",
    "        flatten = tf.layers.flatten(gap)\n",
    "        output = tf.layers.dense(inputs = flatten, units = n_output)\n",
    "        return output\n",
    "\n",
    "    def global_avg_pooling(self, x):\n",
    "        gap = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "        return gap\n",
    "\n",
    "    def inf(self, x):\n",
    "        \"\"\"\n",
    "        conv_1: 1\n",
    "        id_~ + resnet_~: 16 x 3 = 48\n",
    "        fc_lay: 1\n",
    "\n",
    "        total: 50\n",
    "        \"\"\"\n",
    "        conv_1 = self.conv(x, self.ch, strides = (2, 2))\n",
    "        maxp_1 = self.maxp(conv_1)\n",
    "        se_1 = self.SE_res_stage(maxp_1, self.r_ch_1, downsample = False, n_rep = 3)\n",
    "        se_2 = self.SE_res_stage(se_1, self.r_ch_2, downsample = True, n_rep = 4)\n",
    "        se_3 = self.SE_res_stage(se_2, self.r_ch_3, downsample = True, n_rep = 6)\n",
    "        se_4 = self.SE_res_stage(se_3, self.r_ch_4, downsample = True, n_rep = 3)\n",
    "        gap = self.global_avg_pooling(se_4)\n",
    "        score = self.fc_layer(gap, n_output)\n",
    "        return score\n",
    "\n",
    "    \n",
    "model = SEResNet50(ch, r_ch_1, r_ch_2, r_ch_3, r_ch_4)\n",
    "score = model.inf(x)\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=score)\n",
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:48:03.703711Z",
     "start_time": "2019-12-14T21:08:12.546072Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "[Iter] || Train_accr || Valid_accr || Train_loss || Valid_loss\n",
      "==============================================================\n",
      "[***0] || 12.50 %    || 10.94 %    || 2.32614183 || 2.33273935\n",
      "--------------------------------------------------------------\n",
      "[***0] || 21.88 %    || 3.12 %    || 2.63688850 || 2.73295856\n",
      "--------------------------------------------------------------\n",
      "[***0] || 15.62 %    || 7.81 %    || 2.32405353 || 2.57484293\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1215 06:09:25.053755 139752795641600 deprecation.py:323] From /home/yunseob/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[***0] || 65.62 %    || 45.31 %    || 0.90970403 || 1.18471181\n",
      "--------------------------------------------------------------\n",
      "[***0] || 75.00 %    || 78.12 %    || 0.56642854 || 0.52714074\n",
      "--------------------------------------------------------------\n",
      "[***0] || 96.88 %    || 87.50 %    || 0.21465579 || 0.44611055\n",
      "--------------------------------------------------------------\n",
      "[***0] || 96.88 %    || 92.19 %    || 0.20382050 || 0.29965836\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 96.88 %    || 0.08867019 || 0.13591471\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 95.31 %    || 0.04378865 || 0.13898696\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 98.44 %    || 0.03086498 || 0.05751421\n",
      "--------------------------------------------------------------\n",
      "[***0] || 96.88 %    || 100.00 %    || 0.05434183 || 0.03088571\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.01707105 || 0.01790744\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.01203890 || 0.02211237\n",
      "--------------------------------------------------------------\n",
      "[***0] || 96.88 %    || 100.00 %    || 0.05434664 || 0.01390026\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.01106212 || 0.01419214\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00531374 || 0.00365629\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00417101 || 0.00912830\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00294327 || 0.00603782\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00305453 || 0.00441944\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00272611 || 0.00817377\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00515549 || 0.01451614\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00197870 || 0.00174670\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.01679150 || 0.00643824\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00128961 || 0.00122566\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00122289 || 0.00216916\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00125799 || 0.00154823\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00085767 || 0.00080097\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 98.44 %    || 0.00051415 || 0.02801282\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00100588 || 0.00213871\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00046820 || 0.00083512\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00062071 || 0.00131244\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00056804 || 0.00107609\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00035499 || 0.00173760\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00062943 || 0.00055294\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00034831 || 0.00076238\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00023949 || 0.00041243\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00049580 || 0.00086884\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00158564 || 0.00070518\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00043391 || 0.00028932\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00019997 || 0.00031113\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00025379 || 0.00023104\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00018002 || 0.00038976\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00018239 || 0.00030248\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00030718 || 0.00031625\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00018685 || 0.00027640\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00035727 || 0.00025932\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00014635 || 0.00088410\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00020694 || 0.00051866\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00013601 || 0.00018739\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00031949 || 0.00011546\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00016519 || 0.00022934\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00013371 || 0.00012846\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00013901 || 0.00011545\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00024310 || 0.00007644\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00015175 || 0.00038130\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00012176 || 0.00943566\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00015210 || 0.00048756\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00010253 || 0.00018267\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00018942 || 0.00010720\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006978 || 0.00007270\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00155604 || 0.00173174\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00005734 || 0.00004936\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00012419 || 0.00017160\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00008492 || 0.00013142\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00005826 || 0.00007274\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006860 || 0.00014994\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004776 || 0.00006546\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00007665 || 0.00006858\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[***0] || 100.00 %    || 100.00 %    || 0.00026024 || 0.00025635\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00010612 || 0.00013132\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006883 || 0.00006069\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00014473 || 0.00007671\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003828 || 0.00007558\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00008326 || 0.00007902\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004301 || 0.00006336\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003841 || 0.00004882\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002995 || 0.00006488\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00017981 || 0.00009566\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004899 || 0.00011980\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003637 || 0.00004328\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004267 || 0.00004349\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004547 || 0.00012598\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004080 || 0.00004291\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004244 || 0.00005432\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003563 || 0.00006321\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00009933 || 0.00002870\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003343 || 0.00002720\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006482 || 0.00004626\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002624 || 0.00003474\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00173142 || 0.00024182\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00008627 || 0.00005495\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002604 || 0.00004413\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003213 || 0.00003295\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004799 || 0.00003652\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002173 || 0.00002520\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004896 || 0.00004357\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003811 || 0.00002473\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001589 || 0.00003032\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002775 || 0.00004005\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001278 || 0.00002328\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001972 || 0.00002293\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002430 || 0.00001325\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002304 || 0.00002745\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00005059 || 0.00010417\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003138 || 0.00001958\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003609 || 0.00004716\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001547 || 0.00003001\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002728 || 0.00002487\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00005241 || 0.00001749\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00018557 || 0.00003946\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002924 || 0.00003354\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001710 || 0.00001785\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002326 || 0.00001254\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000879 || 0.00001166\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001150 || 0.00001432\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00007413 || 0.00005566\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006514 || 0.00002877\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001807 || 0.00001027\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002385 || 0.00003326\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001090 || 0.00002688\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001261 || 0.00001352\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006352 || 0.00033739\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001329 || 0.00002181\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000838 || 0.00001018\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00027804 || 0.00003645\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002076 || 0.00002398\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001273 || 0.00001233\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001550 || 0.00000798\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000847 || 0.00001630\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001240 || 0.00001021\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00006361 || 0.00004781\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002709 || 0.00001014\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001045 || 0.00001429\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[***0] || 100.00 %    || 100.00 %    || 0.00002741 || 0.00004602\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002047 || 0.00001378\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000738 || 0.00001473\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001127 || 0.00000866\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001176 || 0.00001860\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000635 || 0.00001022\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001334 || 0.00000860\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001395 || 0.00001125\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00003698 || 0.00001521\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001556 || 0.00001080\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001647 || 0.00007376\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00002280 || 0.00001024\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001398 || 0.00001072\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000842 || 0.00001165\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001895 || 0.00001026\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00004030 || 0.00001423\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000688 || 0.00000822\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000528 || 0.00000894\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000649 || 0.00000546\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001110 || 0.00001020\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000675 || 0.00001065\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001128 || 0.00000954\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001067 || 0.00000788\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000857 || 0.00000788\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000599 || 0.00001090\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000540 || 0.00000721\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000541 || 0.00000612\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000530 || 0.00000696\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000579 || 0.00000917\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000499 || 0.00000452\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000286 || 0.00000343\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000361 || 0.00000377\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000390 || 0.00000876\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000404 || 0.00000522\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000297 || 0.00000460\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000452 || 0.00000467\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000239 || 0.00000462\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000426 || 0.00000462\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000503 || 0.00001484\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000687 || 0.00000625\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000400 || 0.00000563\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000773 || 0.00000773\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000554 || 0.00000456\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000279 || 0.00000466\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000506 || 0.00000521\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000248 || 0.00000441\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001110 || 0.00000455\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000777 || 0.00000598\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000339 || 0.00000627\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001374 || 0.00002020\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000393 || 0.00001950\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000317 || 0.00000766\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001174 || 0.00001143\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001112 || 0.00001212\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000647 || 0.00000670\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000684 || 0.00000544\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000584 || 0.00001354\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000831 || 0.00000450\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000364 || 0.00000355\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000991 || 0.00000607\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000402 || 0.00000596\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001575 || 0.00000568\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000190 || 0.00000328\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000278 || 0.00000311\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00000655 || 0.00006154\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[***0] || 100.00 %    || 100.00 %    || 0.00000747 || 0.00002559\n",
      "--------------------------------------------------------------\n",
      "[***0] || 100.00 %    || 100.00 %    || 0.00001025 || 0.00001071\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5c42ccd1a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/disk1/yunseob/courses/19-2_computer vision/history/SEResNet50_STFT_ch_accr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccr_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disk1/yunseob/courses/19-2_computer vision/utils.py\u001b[0m in \u001b[0;36mdone\u001b[0;34m(self, train_time, early_stopping)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "t_batch = 32\n",
    "v_batch = 64\n",
    "n_cal = 10\n",
    "n_prt = 100\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "# LR = 1e-4 # 1e-4 ~ 5e-4 (xavier)\n",
    "lr = 1e-4\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optm = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "# optm = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "start_time = time.time() \n",
    "\n",
    "accr_train, accr_valid, loss_train, loss_valid = [], [], [], []\n",
    "early_stopping = False\n",
    "\n",
    "hist = training_history(n_iter, accr_train, accr_valid, loss_train, loss_valid)\n",
    "hist.table()\n",
    "\n",
    "while True:\n",
    "    train_x, train_y = random_minibatch(train_X, train_Y, batch_size = t_batch)\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    \n",
    "    sess.run(optm, feed_dict = {'img:0': train_x, 'label:0': train_y, 'bn_prob:0' :1})\n",
    "    n_iter += 1\n",
    "    if n_iter % n_cal == 0:\n",
    "        c, p = sess.run([loss, score], feed_dict = {'img:0': train_x, 'label:0': train_y, 'bn_prob:0' :0})\n",
    "\n",
    "        p = np.argmax(p, axis = 1)\n",
    "        l = np.argmax(train_y, axis = 1)\n",
    "        a = np.mean(np.equal(p, l))\n",
    "        \n",
    "        valid_x, valid_y = random_minibatch(valid_X, valid_Y, batch_size = v_batch)\n",
    "        c_valid, p_valid = sess.run([loss, score], feed_dict = {'img:0': valid_x, 'label:0': valid_y, 'bn_prob:0' :0})\n",
    "\n",
    "        p_valid = np.argmax(p_valid, axis = 1)\n",
    "        l_valid = np.argmax(valid_y, axis = 1)\n",
    "        a_valid = np.mean(np.equal(p_valid, l_valid))\n",
    "\n",
    "        accr_valid.append(a_valid)\n",
    "        loss_valid.append(c_valid)\n",
    "        accr_train.append(a)\n",
    "        loss_train.append(c)\n",
    "\n",
    "        if n_iter % n_prt == 0:\n",
    "            hist.prt_evl()\n",
    "            \n",
    "        if loss_valid[-1] == np.min(loss_valid):\n",
    "            now = datetime.datetime.now()\n",
    "            nowDatetime = now.strftime('%y%m%d%H%M')\n",
    "            model_name = 'stft_ch_seres50_{0}_{1}_val_acc_{2:.2f}_val_loss_{3:.6f}'.format(nowDatetime, n_iter, accr_valid[-1], loss_valid[-1])\n",
    "            saver.save(sess, './model/STFT/' + model_name)\n",
    "        if n_iter == 20000:\n",
    "            break\n",
    "#         if n_iter > 1000:\n",
    "#             if np.max(accr_train) < 0.9:\n",
    "#                 if np.mean(loss_train[-50:-30]) <= np.mean(loss_train[-30:]) :\n",
    "#                     hist.early_under()\n",
    "#                     early_stopping = True\n",
    "#                     break\n",
    "#             if np.mean(accr_train[-50:]) >= 0.995:\n",
    "#                 if (\n",
    "#                     np.mean(loss_valid[-41:-21]) <= np.mean(loss_valid[-21:-1]) and\n",
    "#                     loss_valid[-1] < loss_valid[-2] # np.min(loss_valid[-20:]) == loss_valid[-1]\n",
    "#                     ):\n",
    "#                     hist.early_over()\n",
    "#                     early_stopping = True\n",
    "#                     break          \n",
    "\n",
    "train_time = int((time.time() - start_time)/60)  \n",
    "hist.done(train_time, early_stopping)\n",
    "\n",
    "np.save('/mnt/disk1/yunseob/courses/19-2_computer vision/history/SEResNet50_STFT_ch_accr', np.array(accr_train))\n",
    "np.save('/mnt/disk1/yunseob/courses/19-2_computer vision/history/SEResNet50_STFT_ch_loss', np.array(loss_train))\n",
    "\n",
    "history(save = False)   \n",
    "\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:53:12.012382Z",
     "start_time": "2019-12-14T21:53:12.002394Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('/mnt/disk1/yunseob/courses/19-2_computer vision/history/SEResNet50_STFT_ch_accr', np.array(accr_train))\n",
    "np.save('/mnt/disk1/yunseob/courses/19-2_computer vision/history/SEResNet50_STFT_ch_loss', np.array(loss_train))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
