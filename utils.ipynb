{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.774318Z",
     "start_time": "2019-12-14T20:36:30.906513Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.810876Z",
     "start_time": "2019-12-14T20:36:32.778581Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_and_label(data_dir, reshape_need = False, extend = False):\n",
    "\n",
    "    \"\"\"\n",
    "    data_dir:folder including npy files\n",
    "    \"\"\"\n",
    "\n",
    "    npy_files = sorted(os.listdir(data_dir))\n",
    "    npy_files = [i for i in npy_files if target_str in i]\n",
    "\n",
    "    normal = np.load(os.path.join(data_dir, str([i for i in npy_files if 'normal' in i][0])))\n",
    "    ball_7 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'ball_7' in i][0])))\n",
    "    ball_14 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'ball_14' in i][0])))\n",
    "    ball_21 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'ball_21' in i][0])))\n",
    "    inner_7 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'inner_7' in i][0])))\n",
    "    inner_14 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'inner_14' in i][0])))\n",
    "    inner_21 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'inner_21' in i][0])))\n",
    "    outer_7 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'outer_7' in i][0])))\n",
    "    outer_14 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'outer_14' in i][0])))\n",
    "    outer_21 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'outer_21' in i][0])))\n",
    "\n",
    "    normal_y = one_hot(normal, 0, nb_classes = 10)\n",
    "    ball_7_y = one_hot(ball_7, 1, nb_classes = 10)\n",
    "    ball_14_y = one_hot(ball_14, 2, nb_classes = 10)\n",
    "    ball_21_y = one_hot(ball_21, 3, nb_classes = 10)\n",
    "    inner_7_y = one_hot(inner_7, 4, nb_classes = 10)\n",
    "    inner_14_y = one_hot(inner_14, 5, nb_classes = 10)\n",
    "    inner_21_y = one_hot(inner_21, 6, nb_classes = 10)\n",
    "    outer_7_y = one_hot(outer_7, 7, nb_classes = 10)\n",
    "    outer_14_y = one_hot(outer_14, 8, nb_classes = 10)\n",
    "    outer_21_y = one_hot(outer_21, 9, nb_classes = 10)\n",
    "\n",
    "    test_x = np.vstack([normal, ball_7, ball_14, ball_21, inner_7, inner_14, inner_21, outer_7, outer_14, outer_21])\n",
    "    labels = np.vstack([normal_y, ball_7_y, ball_14_y, ball_21_y, inner_7_y, inner_14_y, inner_21_y, outer_7_y, outer_14_y, outer_21_y])\n",
    "\n",
    "    if reshape_need != False:\n",
    "        test_x = reshapeAsimage(test_x)\n",
    "    if extend != False:\n",
    "        test_x = np.expand_dims(test_x, axis = 3)\n",
    "    print(test_x.shape, labels.shape)\n",
    "    return test_x, labels\n",
    "\n",
    "def load_data_and_label_v2(data_dir, target_str = '', reshape_need = False, extend = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    data_dir: A folder including npy.files.\n",
    "    target_str: When there are various type of data, you can sort data by the desired type with 'target_str'\n",
    "    \"\"\"\n",
    "    \n",
    "    npy_files = sorted(os.listdir(data_dir))\n",
    "    npy_files = [i for i in npy_files if target_str in i]\n",
    "\n",
    "    normal = np.load(os.path.join(data_dir, str([i for i in npy_files if 'normal' in i][0])))\n",
    "    ball_7 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'ball_7' in i][0])))\n",
    "    ball_14 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'ball_14' in i][0])))\n",
    "    ball_21 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'ball_21' in i][0])))\n",
    "    inner_7 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'inner_7' in i][0])))\n",
    "    inner_14 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'inner_14' in i][0])))\n",
    "    inner_21 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'inner_21' in i][0])))\n",
    "    outer_7 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'outer_7' in i][0])))\n",
    "    outer_14 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'outer_14' in i][0])))\n",
    "    outer_21 = np.load(os.path.join(data_dir, str([i for i in npy_files if 'outer_21' in i][0])))\n",
    "\n",
    "    normal_y = one_hot(normal, 0, nb_classes = 10)\n",
    "    ball_7_y = one_hot(ball_7, 1, nb_classes = 10)\n",
    "    ball_14_y = one_hot(ball_14, 2, nb_classes = 10)\n",
    "    ball_21_y = one_hot(ball_21, 3, nb_classes = 10)\n",
    "    inner_7_y = one_hot(inner_7, 4, nb_classes = 10)\n",
    "    inner_14_y = one_hot(inner_14, 5, nb_classes = 10)\n",
    "    inner_21_y = one_hot(inner_21, 6, nb_classes = 10)\n",
    "    outer_7_y = one_hot(outer_7, 7, nb_classes = 10)\n",
    "    outer_14_y = one_hot(outer_14, 8, nb_classes = 10)\n",
    "    outer_21_y = one_hot(outer_21, 9, nb_classes = 10)\n",
    "\n",
    "    test_x = np.vstack([normal, ball_7, ball_14, ball_21, inner_7, inner_14, inner_21, outer_7, outer_14, outer_21])\n",
    "    labels = np.vstack([normal_y, ball_7_y, ball_14_y, ball_21_y, inner_7_y, inner_14_y, inner_21_y, outer_7_y, outer_14_y, outer_21_y])\n",
    "\n",
    "    if reshape_need != False:\n",
    "        test_x = reshapeAsimage(test_x)\n",
    "    if extend != False:\n",
    "        test_x = np.expand_dims(test_x, axis = 3)\n",
    "    print(test_x.shape, labels.shape)\n",
    "    return test_x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.820005Z",
     "start_time": "2019-12-14T20:36:32.813842Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(data, classes, nb_classes = 2):\n",
    "    one_hot = [0]*nb_classes\n",
    "    one_hot[classes] = 1\n",
    "    return np.vstack([one_hot for i in range(len(data))])\n",
    "\n",
    "\n",
    "def reshapeAsimage(data):\n",
    "    \"\"\"\n",
    "    inputshape = (Number, Channel, Height(f), Width(t))\n",
    "    outputshape = (Number, Height(f), Width(t), Channel)\n",
    "    \"\"\"\n",
    "    N, H, W, C = data.shape[0], data.shape[2], data.shape[3], data.shape[1]\n",
    "    reshape = np.zeros([N, H, W, C])\n",
    "    for n in range(N):\n",
    "        for f in range(H):\n",
    "            for t in range(W):\n",
    "                for c in range(C):\n",
    "                    reshape[n, f, t, c] = data[n, c, f, t]\n",
    "    return reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.832864Z",
     "start_time": "2019-12-14T20:36:32.822305Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_valid_split(data, label, train_rate = 0.85):\n",
    "    train_idx = np.sort(np.random.choice(len(data), round(len(data)*train_rate), replace = False))\n",
    "    valid_idx = np.setxor1d(train_idx, np.arange(len(data)))\n",
    "    return data[train_idx], label[train_idx], data[valid_idx], label[valid_idx]\n",
    "\n",
    "def random_minibatch(x, y, batch_size = 50):\n",
    "    idx = np.random.choice(len(x), batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "def shuffle(x, y):\n",
    "    idx = np.arange(len(x))\n",
    "    np.random.shuffle(idx)\n",
    "    if type(x) == type(y):\n",
    "        return x[idx], y[idx] \n",
    "    else:\n",
    "        return x[idx]\n",
    "    \n",
    "def history(save = False):\n",
    "    fig = plt.figure(figsize = (15,20))\n",
    "    plt.suptitle('Training History', y = 0.92, fontsize = 20)\n",
    "    \n",
    "    x_axis = range(1, len(accr_train)+1)\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x_axis, accr_train, 'b-', label = 'Training Accuracy')\n",
    "    plt.plot(x_axis, accr_valid, 'r-', label = 'Validation Accuracy')\n",
    "    plt.xlabel('n_iter/n_cal (n_cal = {})'.format(n_cal), fontsize = 15)\n",
    "    plt.ylabel('Accuracy', fontsize = 15)\n",
    "    plt.legend(fontsize = 10)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x_axis, loss_train, 'b-', label = 'Training Loss')\n",
    "    plt.plot(x_axis, loss_valid, 'r-', label = 'Validation Loss')\n",
    "    plt.xlabel('n_iter/n_cal (n_cal = {})'.format(n_cal), fontsize = 15)\n",
    "    plt.ylabel('Loss', fontsize = 15)\n",
    "#     plt.yticks(np.arange(0, 0.25, step=0.025))\n",
    "    plt.legend(fontsize = 12)\n",
    "    plt.show()\n",
    "    if save == True:\n",
    "        fig.savefig(hist_path + filename)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.848601Z",
     "start_time": "2019-12-14T20:36:32.836033Z"
    }
   },
   "outputs": [],
   "source": [
    "class Contents:\n",
    "    def table(self):\n",
    "        print('==============================================================')\n",
    "        print('[Iter] || Train_accr || Valid_accr || Train_loss || Valid_loss')\n",
    "        print('==============================================================')\n",
    "    def evl(self):\n",
    "        evl = '[{0:*>4d}] || {1:*>.2f} %    || {2:*>.2f} %    || {3:.8f} || {4:.8f}'.format(n_iter, \n",
    "                                                                                      accr_train[-1]*100, accr_valid[-1]*100, \n",
    "                                                                                      loss_train[-1], loss_valid[-1])\n",
    "        return evl\n",
    "    def prt_evl(self):\n",
    "        print(self.evl())\n",
    "        print('--------------------------------------------------------------')\n",
    "    def early_under(self):\n",
    "        print(self.evl() + ' [Early stopping - Underffiting !!]\\n')\n",
    "    def early_over(self):\n",
    "        print(self.evl() + ' [Early stopping - Overffiting !!]\\n')\n",
    "    def early(self):\n",
    "        print(self.evl() + ' [Early stopping]\\n')\n",
    "    def done(self):  \n",
    "        global training_name\n",
    "        global contents\n",
    "        global filename\n",
    "        global title\n",
    "        \n",
    "        now = datetime.datetime.now()\n",
    "        nowDatetime = now.strftime('%y%m%d%H%M')\n",
    "        \n",
    "        contents = (\n",
    "        'Training Time : {} Min.\\n'.format(train_time) +\n",
    "        'Early Stopping : {}\\n'.format(early_stopping) +\n",
    "        'Iteration : {}\\n'.format(n_iter)\n",
    "        )\n",
    "        print(contents)\n",
    "\n",
    "        title = '[ResNet-50] Training History'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.863537Z",
     "start_time": "2019-12-14T20:36:32.851667Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet:  \n",
    "    def __init__(self, model_path):\n",
    "        self.test_graph = tf.Graph()\n",
    "        with self.test_graph.as_default():\n",
    "            self.sess = tf.Session(graph = self.test_graph)\n",
    "            loader = tf.train.import_meta_graph(model_path + '.meta')\n",
    "            loader.restore(self.sess, model_path)\n",
    "\n",
    "            self.bn_prob = self.test_graph.get_tensor_by_name('bn_prob:0')\n",
    "            self.x = self.test_graph.get_tensor_by_name('img:0')\n",
    "            self.score = self.test_graph.get_tensor_by_name('dense/BiasAdd:0')\n",
    "\n",
    "    def get_softmax(self, image):\n",
    "        softmax = self.sess.run(tf.nn.softmax(self.score), feed_dict={self.x: image, self.bn_prob: False})\n",
    "        return softmax\n",
    "    \n",
    "class VGGNet:  \n",
    "    def __init__(self, model_path):\n",
    "        self.test_graph = tf.Graph()\n",
    "        with self.test_graph.as_default():\n",
    "            self.sess = tf.Session(graph = self.test_graph)\n",
    "            loader = tf.train.import_meta_graph(model_path + '.meta')\n",
    "            loader.restore(self.sess, model_path)\n",
    "\n",
    "            self.is_training = self.test_graph.get_tensor_by_name('is_training:0')\n",
    "            self.x = self.test_graph.get_tensor_by_name('img:0')\n",
    "            self.score = self.test_graph.get_tensor_by_name('dense_2/BiasAdd:0')\n",
    "\n",
    "    def get_softmax(self, image):\n",
    "        softmax = self.sess.run(tf.nn.softmax(self.score), feed_dict={self.x: image, self.is_training: False})\n",
    "        return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.876058Z",
     "start_time": "2019-12-14T20:36:32.867268Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_batch_idxs(data, batch_size = None):\n",
    "    \"\"\"generate the serial batch of data on index-level.\n",
    "       Usually, the data is too large to be evaluated at once.\n",
    "    \n",
    "    Args:\n",
    "      data: A list or array of target dataset e.g. data_x we use\n",
    "      batchsize: A integer\n",
    "      \n",
    "    Returns:\n",
    "      batch_idxs: A list, \n",
    "    \"\"\"\n",
    "    if batch_size == None:\n",
    "        batch_size = 250\n",
    "    \n",
    "    total_size = len(data)\n",
    "    batch_idxs = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        if total_size >= start + batch_size:\n",
    "            batch_idxs.append([start + i for i in range(batch_size)])\n",
    "        elif total_size < start + batch_size:\n",
    "            batch_idxs.append([start + i for i in range(total_size - start)])\n",
    "        start += batch_size\n",
    "        if total_size <= start:\n",
    "            break\n",
    "    return batch_idxs\n",
    "\n",
    "def batch_flatten(data):\n",
    "    \"\"\"flatten A list stacked with the result of batch.\n",
    "    \n",
    "    Args:\n",
    "      data: A list or array  \n",
    "      \n",
    "    Returns:\n",
    "      Data: A list, total result\n",
    "    \"\"\"\n",
    "    batch_n = len(data)\n",
    "    for i in range(batch_n):\n",
    "        if i == 0:\n",
    "            Data = data[i]\n",
    "        else:\n",
    "            Data = np.concatenate((Data, data[i]), axis = 0)   \n",
    "    return Data\n",
    "\n",
    "def model_pred(Model, image, n_batch):\n",
    "    b_idxs = test_batch_idxs(image, batch_size = n_batch)\n",
    "    outputs = []\n",
    "    start_time = time.time()\n",
    "    for b_idx in b_idxs:\n",
    "        softmax = Model.get_softmax(image[b_idx])\n",
    "        outputs.append(softmax)\n",
    "    time_taken = time.time() - start_time\n",
    "    print(\"Inference Time:\",time.strftime(\"%H:%M:%S\", time.gmtime(time_taken)))\n",
    "    outputs = batch_flatten(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T20:36:32.888034Z",
     "start_time": "2019-12-14T20:36:32.878629Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(data_y, outputs):\n",
    "    pred = np.argmax(outputs, axis = 1)\n",
    "    true = np.argmax(data_y, axis = 1)\n",
    "    acc = 100*np.mean(np.equal(true, pred))\n",
    "    print(\"Accuracy: {:.2f} %\".format(acc))\n",
    "    return acc\n",
    "\n",
    "def con_mat(data_y, outputs):\n",
    "    pred = np.argmax(outputs, axis = 1)\n",
    "    true = np.argmax(data_y, axis = 1)\n",
    "    return confusion_matrix(true, pred)\n",
    "\n",
    "def plot_con_mat(cm, value_size = 15, label_size = 10, mode = 'percent'):\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Blues)\n",
    "    thresh = cm.max()/2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if mode == 'percent':\n",
    "            value = np.round(cm[i, j]/(np.sum(cm, 1)[i]), 3)\n",
    "        if mode == 'num':\n",
    "            value = cm[i, j]\n",
    "        plt.text(j, i, value,\n",
    "                 fontsize = value_size,\n",
    "                 horizontalalignment = 'center',\n",
    "                 color = 'white' if cm[i, j] > thresh else 'black')\n",
    "    plt.ylabel('True label', fontsize = label_size)\n",
    "    plt.xlabel('Predicted', fontsize = label_size)\n",
    "    plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "               ['nor', 'ball_7', 'ball_14', 'ball_21', 'inner_7', 'inner_14', 'inner_21', 'outer_7', 'outer_14', 'outer_21'], \n",
    "               rotation=-90, fontsize = label_size)\n",
    "    plt.yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "               ['nor', 'ball_7', 'ball_14', 'ball_21', 'inner_7', 'inner_14', 'inner_21', 'outer_7', 'outer_14', 'outer_21'], \n",
    "               rotation=0, fontsize = label_size)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
